---
title: "STAT 139 Final Homework EDA"
author: "Emily Stewart, Tejaswi Polimetla, Theo Lebryk"
date: "2025-11-25"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lme4)
# lmerTest provides p-values for lmer models; install with: install.packages("lmerTest")
# If not installed, we'll use lme4 alone and get p-values via anova()
if (requireNamespace("lmerTest", quietly = TRUE)) {
  library(lmerTest)
}
```

## Introduction

This project will investigate how perception and branding influence coffee ratings, and whether heavier coffee drinkers are better at distinguishing real taste differences in coffee. To study this, we conducted a within-subjects taste test experiment in which each participant sampled three coffees and rated each on a 10 point Likert scale:

1. Coffee 1: Dunkin coffee in Dunkin cup
2. Coffee 2: Dunkin coffee in Flour cup
3. Coffee 3: Swissbakers coffee in Swissbakers cup

Dunkin coffee is considered to be the lowest-quality coffee, with Swissbakers considered to be the highest-quality coffee amongst the three brands. Each participant also provided their weekly coffee consumption (cups/week), which will serve as a proxy for coffee expertise.

Our main research questions are:

1. Can people actually detect a real taste difference between Dunkin coffee and Swissbakers coffee?
2. Can perception/branding alone create an illusory difference in ratings even when the coffee is identical?
3. Do heavier coffee drinkers show a greater ability to detect actual taste differences in coffee?

## Data Description

The data were collected by our group during an in-person coffee tasting held in Winthrop House at Harvard University. Participants were recruited informally from the undergraduate and graduate student community, and all tastings were conducted in the same common space to maintain consistency. Each participant sampled the coffees in a randomized order and rated them independently on a 10-point Likert scale. The experiment used a within-subjects design, meaning every student tasted all three coffees. Because the setting was controlled and all participants completed the tasting in one session, the dataset reflects a clean, structured set of repeated measurements collected under consistent conditions.


```{r}
coffee <- read.csv("coffee_tasting.csv")
head(coffee)
dim(coffee)
```

The dataset contains data from 29 participants, with row per participant with the following variables:

| Variable           | Type           | Description                                                                |
| ------------------ | -------------- | -------------------------------------------------------------------------- |
| **time**           | Character      | Clock time when the participant tasted the coffee                          |
| **time_indicator** | Integer        | Ordered index of tasting times (1 = earliest, increases with session time) |
| **flour**          | Integer (1–10) | Rating of the Dunkin coffee served in a **Flour Bakery** cup               |
| **dunkin**         | Integer (1–10) | Rating of the Dunkin coffee served in a **Dunkin** cup                     |
| **swissbakers**    | Integer (1–10) | Rating of the Swissbakers coffee served in a **Swissbakers** cup           |
| **cupsperweek**    | Integer        | Self-reported number of cups of coffee consumed per week                   |


We will focus on `flour`, `dunkin`, `swissbakers`, and `cupspwerweek` in our analysis.
```{r}
# Remove time variables
coffee_cleaned <- coffee %>% select(-c(time, time_indicator))
```


## ADD IN SOME STUFF ABOUT DATA ASSUMPTIONS LIKE NORMALITY, INDEPENDENCE, ETC.

## Exploratory Data Analysis

Before analyzing the data, we want to verify that the dataset is clean, consistent, and suitable for linear modeling. Because we manually collected this data, there is potential for issues such as missing entries, inconsistent rating ranges, mistyped values, or irregularities in participant-level measurements.

First, we can inspect for missingness.
```{r}
colSums(is.na(coffee))
```

There are no missing values in any column.

#### Univariate Summaries and EDA

Next, we can look at univariate summary statistics for each variable we plan to use in our analysis.
```{r}
summary(coffee_cleaned)
```

The summary statistics indicate that the dataset is clean and aligns with expectations from our tasting experiment. All three coffee rating variables fall within the intended 1-10 scale, with no implausible values. The relative values of the means also appear reasonable with the highest mean rating for Dunkin coffee in a Flour cup and the lowest mean rating for Dunkin coffee in a Dunkin cup. For cups per week, the values range from 0 to 21, which is a plausible range and doesn't contain any negative or extremely high values. The mean of 6.69 cups / week is reasonable. Overall, the summary table seems to indicate there are no data entry problems.

```{r}
coffee_long <- coffee_cleaned %>%
  pivot_longer(cols = c(flour, dunkin, swissbakers), names_to = "coffee_type",
               values_to = "rating")

ggplot(coffee_long, aes(x = rating, fill = coffee_type)) +
  geom_histogram(binwidth = 1, color = "white", alpha = 0.7) +
  facet_wrap(~ coffee_type, nrow = 1) +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Distribution of Coffee Ratings",
       x = "Rating (1–10)",
       y = "Count") +
  theme_bw() +
  theme(legend.position = "none")
```

The histograms show clear differences in the distributions of coffee ratings. Dunkin has a right-skewed distribution, with a majority of ratings falling between 2-4. Flour and Swissbakers follow somewhat bimodal distributions, with Flour having higher peaks around 4 and 6 and Swissbakers have smaller peaks around 2 and 7. These histograms suggest that people generally rated Dunkin coffee poorly and that the branding effects of Flour and Swissbakers had variable effects on different participants.


```{r}
ggplot(coffee_long, aes(x = coffee_type, y = rating, fill = coffee_type)) +
  geom_boxplot(alpha = 0.8) +
  labs(title = "Comparison of Ratings Across Coffee Types",
       x = "Coffee Type",
       y = "Rating") +
  theme_minimal() +
  theme(legend.position = "none")
```

The boxplots show differences in central tendency and spread, with results that are consistent with what we saw in the histograms. Flour has the highest median rating, followed by Swissbakers, and then Dunkin. Here, the Swissbakers distribution appears roughly symmetric with the widest interquartile range. The Flour ratings show a compressed middle range, but extend upward with an outlier at 10. Dunkin shows a roughly symmetric interquartile range, but has a longer upper tail and an outlier at 9. Given the right skew of the Dunking ratings, it may make sense to fit a model with this variable log transformed.



```{r}
ggplot(coffee_cleaned, aes(x = cupsperweek)) +
  geom_histogram(binwidth = 1, color = "white", fill = "lightblue") +
  labs(title = "Distribution of Weekly Coffee Consumption",
       x = "Cups per Week",
       y = "Count") +
  theme_minimal()

ggplot(coffee_cleaned, aes(y = cupsperweek)) +
  geom_boxplot(fill = "lightblue", alpha = 0.8) +
  labs(title = "Boxplot of Weekly Coffee Consumption",
       y = "Cups per Week") +
  theme_minimal()
```

Weekly coffee consumption follows a right-skewed distribution.

## Bivariate EDA

Next, we'll explore relationships between variables, examining how the three coffee ratings relate to one another and how these ratings vary with weekly coffee consumption.

First, we'll take a look at all three pairwise combinations of ratings:
```{r}
ggplot(coffee_cleaned, aes(x = dunkin, y = flour)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Dunkin vs. Flour Ratings",
       x = "Dunkin Rating",
       y = "Flour Rating") +
  theme_minimal()

ggplot(coffee_cleaned, aes(x = dunkin, y = swissbakers)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Dunkin vs. Swissbakers Ratings",
       x = "Dunkin Rating",
       y = "Swissbakers Rating") +
  theme_minimal()

ggplot(coffee_cleaned, aes(x = flour, y = swissbakers)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Flour vs. Swissbakers Ratings",
       x = "Flour Rating",
       y = "Swissbakers Rating") +
  theme_minimal()
```

Across all pairwise comparisons, the scatterplots show positive, though fairly weak linear associations between coffee ratings. This means that across coffee ratings, if a participant gave one coffee a higher rating, they tended to also give the other coffees a higher rating. This relationship is strongest between Swissbakers and Dunkin.


Next, we'll look at correlations between coffee ratings:
```{r}
cor_matrix <- coffee_cleaned %>%
  select(dunkin, flour, swissbakers) %>%
  cor()

cor_matrix
```
The correlation matrix shows that all three coffee ratings are positively, but weakly correlated. The strongest correlation is between Dunkin and Swissbakers ($r \approx 0.34$), consistent with the steeper trend in the scatterplot above. The correlations between Dunkin and Flour and Swissbakers and Flour are pretty similar ($r \approx 0.217 vs 0.208$), again, in line with the weaker relationship we see in the scatterplots.


Next, we'll look at branding effects on taste:
```{r}
coffee_cleaned <- coffee_cleaned %>% mutate(
    branding_diff = flour - dunkin,
    taste_diff = swissbakers - dunkin
  )

ggplot(coffee_cleaned, aes(x = branding_diff)) +
  geom_histogram(binwidth = 1, fill = "lightgreen", color = "white") +
  labs(title = "Branding Effect (Flour - Dunkin)",
       x = "Difference in Rating",
       y = "Count") +
  theme_minimal()

ggplot(coffee_cleaned, aes(x = taste_diff)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "white") +
  labs(title = "Taste Difference (Swissbakers - Dunkin)",
       x = "Difference in Rating",
       y = "Count") +
  theme_minimal()

```

In the first histogram, we see a distribution of the difference in ratings between coffee in Flour vs Dunkin cups to get a sense of the branding effect. This distribution spans 0, though most values are greater than 0, indicating that most participants rated the coffee in the Flour cup more highly than the coffee in the Dunkin cup.

In the second histogram, we see a distribution of the difference between the Swissbakers coffee and the Dunkin coffee in Dunkin cups to get a sense of taste differences by quality. Again, this distribution spans 0, though most values are greater than 0, indicating that people did rate the higher quality Swissbakers coffee more highly than Dunkin coffee.


Finally, we'll look at the difference in coffee ratings for Dunkin and Flour vs weekly coffee consumption:
```{r}
ggplot(coffee_cleaned, aes(x = cupsperweek, y = taste_diff)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Taste Difference vs Coffee Consumption",
       x = "Cups per Week",
       y = "Swissbakers - Dunkin") +
  theme_minimal()
```

This scatterplot shows a weak, positive association between weekly coffee consumption and the difference in rating of Swissbakers coffee vs Dunkin coffee. This generally indicates that participants who drink more coffee tend to have somewhat higher ratings to Swissbakers vs Dunkin. However, the points are widely dispersed across the full range of consumption levels, including some negative differences among moderate/heavy coffee drinkers and some of the largest rating differences occurring among light coffee drinkers.

## Baseline Models

We will fit two simple linear models. The first model will evaluate mean differences across the three coffees, addressing whether branding or coffee quality appears to influence ratings. The second model will test whether weekly coffee consumption, which is our proxy for coffee expertise, predicts participants' ability to discriminate between the higher-quality coffee and Dunkin.

#### Model 1: Mean Differences in Ratings Across Coffees


Hypotheses:

Let $\mu_1$, $\mu_2$, and $\mu_3$ represent the mean ratings for Dunkin coffee in Dunkin cup, Dunkin coffee in Flour cup, and Swissbakers coffee in Swissbakers cup respectively.

$H_0: \mu_1 = \mu_2 = \mu_3$

$H_A:$ at least one mean differs


We will conduct a one-way ANOVA test using an F-statistic that follows $\sim F_{2, 84?}$ under the null distribution. We set $\alpha = 0.05$.

```{r}
model1 <- lm(rating ~ coffee_type, data = coffee_long)
summary(model1)

anova(model1)
```


The overall F-test gave us an F-statistic = 1.90 with a p-value of 0.1558. Under our $\alpha = 0.05$, this means we do not have evidence that the mean ratings differ across Dunkin, Flour, and Swissbakers in this baseline model, so we fail to reject our null hypothesis. The intercept 4.21 represents the mean rating for Dunkin coffee in a Dunkin cup. Flour's estimate of 1.07 suggests that participants rated Dunkin coffee in a FLour cup slightly higher, on average, compared to Dunkin coffee in a Dunkin cup, the but p-value is not significant under our $\alpha$. The Swissbakers' estimate suggests modestly higher ratings thank Dunkin, but again this is not statistically significant. The $R^2 = 0.0433$, so this model does not explain much of the variability in the data.

#### Model 2: Coffee Expertise vs Ratings


Hypotheses:

Let $\beta_1$ be the slope relating weekly coffee consumption to taste difference between Swissbakers and Dunkin.

$H_0: \beta_1 = 0$ (i.e., there's no relationship between coffee consumption/expertise and taste discrimination)

$H_A: \beta_1 \neq 0$

We will conduct a one-sample t-test using a t-statistic which follows a $\sim t_{27}$. We set $\alpha = 0.05$

```{r}
coffee_cleaned <- coffee_cleaned %>% mutate(taste_diff = swissbakers - dunkin)

model2 <- lm(taste_diff ~ cupsperweek, data = coffee_cleaned)
summary(model2)
```

This test yields a t-statistic = 0.946 with a p-value = 0.357 for the slope estimate. This means that weekly coffee consumption does not significantly predict an ability to taste the difference between Swissbakers and Dunkin coffee. Therefore, we fail to reject our null hypothesis. The intercept of 0.24 is the average taste difference for someone who drinks 0 cups of coffee per week. The slope suggests that for each additional cup of coffee drunk per week, the rating difference between Swissbakers and Dunkin in creases by about 0.08, which is vary small, and as we already stated, not statistically significant.

## Residual Analysis

#### Model 1 Residual Analysis

```{r, fig.show='hold', out.width='75%', fig.align='center'}
plot(model1, which = 1)
plot(model1, which = 2)
```

The residuals vs fitted plot shows that the fitted values only fall into three values which correspond to the three coffee types. The spread looks pretty similar across the three coffee types and is pretty wide, indicating that most of the variability is within groups, not between. There is no clear pattern or curvature, the smoothing line is nearly flat, which suggests no major violations of linearity. There is no strong funnel shape, so our residuals appear to be homoskedastic.

The Q-Q plot shows that the residuals follow the theoretical line closely through most of the distribution, indicating that the normality assumption is largely met in our dataset. There is a slight departure in the lower tail, but these are small given the discrete 1-10 rating scale. There don't appear to be many outliers that would threaten the overall model fit.


#### Model 2 Residual Analysis
```{r, fig.show='hold', out.width='75%', fig.align='center'}
plot(model1, which = 1)
plot(model1, which = 2)
```

The residuals don't appear to sit around a flat line in the residuals vs fitted plot. The smoothing curve fluctuates across the line at 0, suggesting a non-linear pattern, meaning the relationship between coffee consumption and taste difference may not be purely linear. The vertical spread of the residuals increases as the fitted values decrease, indicating heteroskedasticity. Given the violations of linearity, we may want to transform weekly coffee consumpion in our final model.

In the Q-Q plot, the residuals align pretty well with the theoretical line, approximating normality. The upper tail dips a bit below the line, indicating thin tails with a few potentially influential points. However, these deviations aren't severe enough to indicate that our data deviates far from normality.


## Extrema Analysis


## Modeling

The baseline models above treated observations as independent, but our data has a within-subjects design where each participant rated all three coffees. We now fit mixed effects models that account for this repeated measures structure by including participant as a random effect.

### Model 3: Mixed Effects Model for Coffee Type Differences

We fit a mixed effects model with participant as a random intercept to account for individual differences in baseline ratings.

```{r}
# Create participant ID - each participant has 3 rows (one per coffee type)
coffee_long <- coffee_long %>%
  mutate(participant_id = rep(1:29, each = 3))

# Fit mixed effects model
model3 <- lmer(rating ~ coffee_type + (1 | participant_id), data = coffee_long)
summary(model3)

# Test for coffee type effect
anova(model3)
# If lmerTest is loaded, this will show p-values; otherwise shows F-values
```

The mixed effects model shows [results will appear here]. The random intercept for participant accounts for the correlation between ratings from the same person. The F-test tests whether mean ratings differ across coffee types.

To test our specific research questions, we examine the estimated differences:

```{r}
# Extract fixed effects
fixef(model3)

# Branding effect: Flour - Dunkin (same coffee, different cup)
branding_effect <- fixef(model3)["coffee_typeflour"]
cat("Branding effect (Flour - Dunkin):", round(branding_effect, 3), "\n")

# Taste effect: Swissbakers - Dunkin (different coffee)
taste_effect <- fixef(model3)["coffee_typeswissbakers"]
cat("Taste effect (Swissbakers - Dunkin):", round(taste_effect, 3), "\n")
```

### Model 4: Testing Expertise Moderation

We now test whether coffee consumption (expertise) moderates the ability to detect taste differences by including an interaction between coffee type and cups per week.

```{r}
# Add cups per week to long format
# Ensure participant_id exists (in case this chunk is run independently)
if (!"participant_id" %in% names(coffee_long)) {
  coffee_long <- coffee_long %>%
    mutate(participant_id = rep(1:29, each = 3))
}

# Add cupsperweek by replicating each participant's value 3 times
coffee_long <- coffee_long %>%
  mutate(cupsperweek = rep(coffee$cupsperweek, each = 3))

# Verify cupsperweek was added
head(coffee_long %>% select(participant_id, coffee_type, rating, cupsperweek))

# Fit model with interaction
model4 <- lmer(rating ~ coffee_type * cupsperweek + (1 | participant_id), 
               data = coffee_long)
summary(model4)

# Test for effects
anova(model4)
# If lmerTest is loaded, this will show p-values; otherwise shows F-values
```

The interaction term tests whether the relationship between coffee type and rating depends on weekly coffee consumption. Specifically, we're interested in whether the Swissbakers vs Dunkin difference is larger for heavier coffee drinkers.

### Model Comparison

We compare the models to see if including expertise improves model fit:

```{r}
# Compare models
AIC(model3, model4)
BIC(model3, model4)

# Likelihood ratio test
anova(model3, model4)
```

### Model Diagnostics

We check the assumptions of our final model:

```{r, fig.show='hold', out.width='75%', fig.align='center'}
# Residual plots
plot(model4, which = 1)
plot(model4, which = 2)

# Check random effects
qqnorm(ranef(model4)$participant_id[[1]], main = "Q-Q plot of random intercepts")
qqline(ranef(model4)$participant_id[[1]])
```

## Conclusion
